{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Dive into Few-Shot Learning ğŸš€\n",
    "\n",
    "In this exercise, you'll:\n",
    "\n",
    "1. Learn about the few-shot-learning concept and ways to tackle it.\n",
    "2. Get a walkthrough of the `Few-Shot-Bench` code base. This code base offers a structured way to compare various methods meta-learning methods an various datasets. Depending on the project you choose, this might be helpful.\n",
    "\n",
    "Let's get started and explore this together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# 0.0 Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.26.0)\n",
      "Requirement already satisfied: pandas in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.0.3)\n",
      "Requirement already satisfied: torch in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.16.0)\n",
      "Collecting anndata (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for anndata from https://files.pythonhosted.org/packages/8a/87/201514af3bf08db52e11b7d94e6129f0a75503194b81614ff48883101c4c/anndata-0.10.3-py3-none-any.whl.metadata\n",
      "  Downloading anndata-0.10.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting h5py (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/6c/ad/0ace9cb2e36e57fa64e59a0a8a5a72e10151d5924cdd36e916e666fdd9da/h5py-3.10.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading h5py-3.10.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (3.7.2)\n",
      "Collecting scanpy (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for scanpy from https://files.pythonhosted.org/packages/39/d5/992cb22882523b873b981c1bdebbf28baffeb7ac931cd5d60cb53f2d8a24/scanpy-1.9.6-py3-none-any.whl.metadata\n",
      "  Downloading scanpy-1.9.6-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.11.1)\n",
      "Requirement already satisfied: seaborn in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (0.12.2)\n",
      "Requirement already satisfied: notebook in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (6.5.4)\n",
      "Collecting prettytable (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for prettytable from https://files.pythonhosted.org/packages/4d/81/316b6a55a0d1f327d04cc7b0ba9d04058cb62de6c3a4d4b0df280cbe3b0b/prettytable-3.9.0-py3-none-any.whl.metadata\n",
      "  Downloading prettytable-3.9.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting goatools (from -r requirements.txt (line 14))\n",
      "  Obtaining dependency information for goatools from https://files.pythonhosted.org/packages/98/6d/8c3a3f2b77c17ef37e96d69ee49ef62c18d72d2c6e507fa5046d6f47082e/goatools-1.3.11-py3-none-any.whl.metadata\n",
      "  Downloading goatools-1.3.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyarrow in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (11.0.0)\n",
      "Collecting pyfastx (from -r requirements.txt (line 16))\n",
      "  Obtaining dependency information for pyfastx from https://files.pythonhosted.org/packages/0d/12/761e4596d11b8d6ab7aa7d31ebec02ab7d16ec1f7e1860622b2748cccc88/pyfastx-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading pyfastx-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (30 kB)\n",
      "Collecting einops (from -r requirements.txt (line 17))\n",
      "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dataclasses-json (from -r requirements.txt (line 18))\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting dataclasses (from -r requirements.txt (line 19))\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting torch_geometric (from -r requirements.txt (line 20))\n",
      "  Obtaining dependency information for torch_geometric from https://files.pythonhosted.org/packages/65/4e/6f9a75548a93fedcd4514ae2de9bee1e91bade6b73252b4da32f0e42ac52/torch_geometric-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting biopython (from -r requirements.txt (line 21))\n",
      "  Downloading biopython-1.81-cp39-cp39-macosx_10_9_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets (from -r requirements.txt (line 22))\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting gdown (from -r requirements.txt (line 23))\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: filelock in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (9.4.0)\n",
      "Collecting array-api-compat (from anndata->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for array-api-compat from https://files.pythonhosted.org/packages/10/cf/040c1b046fd43c02d230295e93969c7d100a4c34f4b1ccfaffdf98ef4530/array_api_compat-1.4-py3-none-any.whl.metadata\n",
      "  Downloading array_api_compat-1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from anndata->-r requirements.txt (line 5)) (1.0.4)\n",
      "Collecting natsort (from anndata->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for natsort from https://files.pythonhosted.org/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl.metadata\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=20 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from anndata->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 7)) (5.2.0)\n",
      "Collecting get-annotations (from scanpy->-r requirements.txt (line 8))\n",
      "  Downloading get_annotations-0.1.2-py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: joblib in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from scanpy->-r requirements.txt (line 8)) (1.2.0)\n",
      "Collecting numba>=0.41.0 (from scanpy->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for numba>=0.41.0 from https://files.pythonhosted.org/packages/b5/de/e2ef933a99c502d2ec5dda1a43a74ab98b1b606c0ff17422d42c62a6f00f/numba-0.58.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading numba-0.58.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting patsy (from scanpy->-r requirements.txt (line 8))\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting session-info (from scanpy->-r requirements.txt (line 8))\n",
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting statsmodels>=0.10.0rc2 (from scanpy->-r requirements.txt (line 8))\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-macosx_10_9_x86_64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from scanpy->-r requirements.txt (line 8)) (4.66.1)\n",
      "Collecting umap-learn>=0.3.10 (from scanpy->-r requirements.txt (line 8))\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (6.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (23.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (21.3.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (5.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (5.3.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (7.4.9)\n",
      "Requirement already satisfied: ipython-genutils in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (5.9.2)\n",
      "Requirement already satisfied: nbconvert>=5 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (6.5.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (1.5.6)\n",
      "Requirement already satisfied: ipykernel in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (6.25.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from notebook->-r requirements.txt (line 12)) (0.5.5)\n",
      "Requirement already satisfied: wcwidth in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from prettytable->-r requirements.txt (line 13)) (0.2.5)\n",
      "Collecting xlsxwriter (from goatools->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for xlsxwriter from https://files.pythonhosted.org/packages/f7/3e/05ba2194cd5073602422859c949a4f21310a3c49bf8dccde9e03d4522b11/XlsxWriter-3.1.9-py3-none-any.whl.metadata\n",
      "  Downloading XlsxWriter-3.1.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting openpyxl (from goatools->-r requirements.txt (line 14))\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting docopt (from goatools->-r requirements.txt (line 14))\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydot (from goatools->-r requirements.txt (line 14))\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: rich in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from goatools->-r requirements.txt (line 14)) (13.6.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->-r requirements.txt (line 18))\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->-r requirements.txt (line 18))\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from torch_geometric->-r requirements.txt (line 20)) (5.9.0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets->-r requirements.txt (line 22))\n",
      "  Obtaining dependency information for comm>=0.1.3 from https://files.pythonhosted.org/packages/7b/a6/5fd0242e974914b139451eea0a61ed9fd2e47157e33a67939043c50a94dd/comm-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading comm-0.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipywidgets->-r requirements.txt (line 22)) (8.15.0)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets->-r requirements.txt (line 22))\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets->-r requirements.txt (line 22))\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from gdown->-r requirements.txt (line 23)) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from gdown->-r requirements.txt (line 23)) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 7)) (3.11.0)\n",
      "Requirement already satisfied: backcall in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.1.2)\n",
      "Requirement already satisfied: entrypoints in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jupyter-client>=5.3.4->notebook->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jupyter-core>=4.6.1->notebook->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 12)) (1.23.4)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: lxml in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (4.9.3)\n",
      "Requirement already satisfied: bleach in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbconvert>=5->notebook->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbformat->notebook->-r requirements.txt (line 12)) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from nbformat->notebook->-r requirements.txt (line 12)) (4.17.3)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.41.0->scanpy->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for llvmlite<0.42,>=0.41.0dev0 from https://files.pythonhosted.org/packages/fc/7a/c6741000d767fed4b339fcd4fa65afbc5fe776473d5f9e9c41eceab0a7c6/llvmlite-0.41.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading llvmlite-0.41.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: ptyprocess in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->-r requirements.txt (line 12)) (0.7.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->-r requirements.txt (line 18))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.3.10->scanpy->-r requirements.txt (line 8))\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tbb>=2019.0 (from umap-learn>=0.3.10->scanpy->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for tbb>=2019.0 from https://files.pythonhosted.org/packages/3c/45/23849b7d10766d4a4df7b2fa1825c92e349bf73ba53458ff98765823fbe4/tbb-2021.10.0-py2.py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.whl.metadata\n",
      "  Downloading tbb-2021.10.0-py2.py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.whl.metadata (989 bytes)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from argon2-cffi->notebook->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 23)) (2.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from ipykernel->notebook->-r requirements.txt (line 12)) (1.6.7)\n",
      "Collecting et-xmlfile (from openpyxl->goatools->-r requirements.txt (line 14))\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from rich->goatools->-r requirements.txt (line 14)) (3.0.0)\n",
      "Collecting stdlib_list (from session-info->scanpy->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for stdlib_list from https://files.pythonhosted.org/packages/be/f4/08daf83c6414031b46e883cb5e06286077e52e8e2f1ae4b3662819a211aa/stdlib_list-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading stdlib_list-0.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 12)) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 12)) (0.18.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 12)) (3.5.0)\n",
      "Requirement already satisfied: websocket-client in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 12)) (0.58.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->goatools->-r requirements.txt (line 14)) (0.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: webencodings in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from bleach->nbconvert>=5->notebook->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: executing in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->-r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /Users/ludekcizinsky/miniconda3/envs/cs502/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 12)) (2.21)\n",
      "Downloading anndata-0.10.3-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m396.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp39-cp39-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scanpy-1.9.6-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
      "Downloading goatools-1.3.11-py3-none-any.whl (15.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyfastx-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl (791 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m791.8/791.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading comm-0.2.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.58.1-cp39-cp39-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading array_api_compat-1.4-py3-none-any.whl (29 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m524.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp39-cp39-macosx_10_9_x86_64.whl (31.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tbb-2021.10.0-py2.py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m640.9/640.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stdlib_list-0.9.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: umap-learn, docopt, session-info, pynndescent\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86770 sha256=4088ba6619e8a20a6655c27b06ded62111eb5f8131cf260ae3a08952d24eeffa\n",
      "  Stored in directory: /Users/ludekcizinsky/Library/Caches/pip/wheels/e1/8b/ec/51afd5b0c041b6a7dd5777ceb58cc0d645ba9454cc5a923e96\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=cf129b893c302e568df512dbd81c4fd8cc48347e81f85e4b2b5be779f7c077db\n",
      "  Stored in directory: /Users/ludekcizinsky/Library/Caches/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "  Building wheel for session-info (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=85b090b1fb8edf4bf4bad2ffc66d3d188c087d7a488b40c548a16e4b929d8b46\n",
      "  Stored in directory: /Users/ludekcizinsky/Library/Caches/pip/wheels/d4/fc/2e/00ca60bac7954b84907efd41baa9b4853500eaeec4228410c6\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=abb0e659a7c66b24e1f8d2487729211d86a325a922a5fc986a4de80fbbafe816\n",
      "  Stored in directory: /Users/ludekcizinsky/Library/Caches/pip/wheels/12/f9/4d/ec5ad1c823c710fcc4473669fdcffc8891f4bc398c841af22e\n",
      "Successfully built umap-learn docopt session-info pynndescent\n",
      "Installing collected packages: tbb, pyfastx, docopt, dataclasses, xlsxwriter, widgetsnbextension, stdlib_list, pydot, prettytable, patsy, natsort, mypy-extensions, marshmallow, llvmlite, jupyterlab-widgets, h5py, get-annotations, et-xmlfile, einops, comm, biopython, array-api-compat, typing-inspect, session-info, openpyxl, numba, torch_geometric, statsmodels, pynndescent, gdown, dataclasses-json, anndata, umap-learn, ipywidgets, goatools, scanpy\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.2\n",
      "    Uninstalling comm-0.1.2:\n",
      "      Successfully uninstalled comm-0.1.2\n",
      "Successfully installed anndata-0.10.3 array-api-compat-1.4 biopython-1.81 comm-0.2.0 dataclasses-0.6 dataclasses-json-0.6.1 docopt-0.6.2 einops-0.7.0 et-xmlfile-1.1.0 gdown-4.7.1 get-annotations-0.1.2 goatools-1.3.11 h5py-3.10.0 ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 llvmlite-0.41.1 marshmallow-3.20.1 mypy-extensions-1.0.0 natsort-8.4.0 numba-0.58.1 openpyxl-3.1.2 patsy-0.5.3 prettytable-3.9.0 pydot-1.4.2 pyfastx-2.0.1 pynndescent-0.5.10 scanpy-1.9.6 session-info-1.0.0 statsmodels-0.14.0 stdlib_list-0.9.0 tbb-2021.10.0 torch_geometric-2.4.0 typing-inspect-0.9.0 umap-learn-0.5.4 widgetsnbextension-4.0.9 xlsxwriter-3.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABC\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from fcnet import FCNet\n",
    "import display_utils\n",
    "import gdown\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=1a3IFmUMUXBH8trx_VWKZEGteRiotOkZS&export=download\n",
      "From (redirected): https://drive.google.com/uc?id=1a3IFmUMUXBH8trx_VWKZEGteRiotOkZS&export=download&confirm=t&uuid=6cd4b9ec-5981-4ec2-b498-2e0ce01e7845\n",
      "To: /Users/ludekcizinsky/Dev/personal/epfl-cs502/coursework/exercises/w8/swissprot.zip\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180M/180M [00:19<00:00, 9.06MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://drive.google.com/u/0/uc?id=1a3IFmUMUXBH8trx_VWKZEGteRiotOkZS&export=download'\n",
    "\n",
    "if os.path.exists('swissprot.zip'):\n",
    "    print('File already downloaded.')\n",
    "else:\n",
    "    output = 'swissprot.zip'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "    print('Download completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q swissprot.zip\n",
    "\n",
    "!rm -rf swissprot.zip\n",
    "clear_output()\n",
    "\n",
    "!mv data/swissprot/go-basic.obo ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n"
     ]
    }
   ],
   "source": [
    "from utils import get_samples_using_ic, check_min_samples, get_mode_ids, encodings, get_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "# 1.0 [Protonet](https://arxiv.org/abs/1703.05175)\n",
    "\n",
    "Imagine trying to recognize and classify new objects after seeing them just once or a few times. It's a tough task for most machine learning models. This is called few-shot classification. Humans can often identify objects even after seeing them just once. So, how can we make machines do that too?\n",
    "\n",
    "Prototype networks work on a basic idea: objects of the same type should be similar to each other in some way. So, in a space where the data is mapped tp, objects from the same class are expected to cluster around a central point, or a 'prototype'. When a new object comes in, the network checks which prototype it's closest to and classifies it accordingly.\n",
    "\n",
    "This method not only works for cases where we have a few examples but also for zero-shot learning, where we have no prior examples at all! Instead, we use a high-level description to determine the prototype.\n",
    "\n",
    "In short, prototype networks help in classifying new objects by looking for similarities to known prototypes, making them both efficient and effective for tasks with limited data.\n",
    "\n",
    "## 1.1 Creating a Meta-Template for Few-Shot Tasks\n",
    "In this exercise, we'll focus on implementing the Protonet using the `Few-Shot-Bench` code base. This code base offers a structured way to compare various methods. It has a template designed to add new methods and assess their performance seamlessly.\n",
    "\n",
    "The template has a standard training and testing cycle for meta-learning techniques. To train and test our model, we have two primary tasks:\n",
    "\n",
    "Mapping our data to the embeddings space: This step is facilitated by the parse_features function. Through this function, we'll calculate the prototypes (or support) and queries (or embeddings) for each data point.\n",
    "\n",
    "Evaluating our model's performance: The correct function will help us with this. It measures how accurately our model classifies data.\n",
    "\n",
    "Your task is to complete the implementation of the `parse_features` and `correct` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaTemplate(nn.Module):\n",
    "    def __init__(self, backbone, n_way, n_support):\n",
    "        super(MetaTemplate, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.n_support = n_support\n",
    "        self.n_query = -1  # (change depends on input)\n",
    "        self.feature = backbone\n",
    "        self.feat_dim = self.feature.final_feat_dim\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_forward(self, x, is_feature=False):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_forward_loss(self, x):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature.forward(x)\n",
    "        return out\n",
    "\n",
    "    def parse_feature(self, x):\n",
    "        '''\n",
    "        :param x: [n_way, n_support + n_query, **embedding_dim]\n",
    "        '''\n",
    "        x = Variable(x.to(self.device))\n",
    "        x = x.contiguous().view(self.n_way * (self.n_support + self.n_query), * x.size()[2:])\n",
    "        # Compute support and query feature.\n",
    "        z_all = ...\n",
    "\n",
    "        # Reverse the transformation to distribute the samples based on the dimensions of their individual categories and flatten the embeddings.\n",
    "        z_all = ...\n",
    "\n",
    "        # Extract the support and query features.\n",
    "        z_support = ...\n",
    "        z_query = ...\n",
    "\n",
    "        return z_support, z_query\n",
    "\n",
    "    def correct(self, x):\n",
    "        # Compute the predictions scores.\n",
    "        scores = ...\n",
    "\n",
    "        # Compute the top1 elements.\n",
    "        topk_scores, topk_labels = ...\n",
    "\n",
    "        # Detach the variables.\n",
    "        topk_ind = ...\n",
    "\n",
    "        # Create the category labels for the queries.\n",
    "        y_query = ...\n",
    "\n",
    "        # Compute number of elements that are correctly classified.\n",
    "        top1_correct = ...\n",
    "        return float(top1_correct), len(y_query)\n",
    "\n",
    "    def train_loop(self, epoch, train_loader, optimizer):\n",
    "        print_freq = 10\n",
    "\n",
    "        avg_loss = 0\n",
    "        for i, (x, _) in enumerate(train_loader):\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.set_forward_loss(x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss = avg_loss + loss.item()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Epoch {:d} | Batch {:d}/{:d} | Loss {:f}'.format(epoch, i, len(train_loader),\n",
    "                                                                        avg_loss / float(i + 1)))\n",
    "        return avg_loss/len(train_loader)\n",
    "    \n",
    "    def test_loop(self, epoch, test_loader, record=None, return_std=False):\n",
    "        acc_all = []\n",
    "\n",
    "        iter_num = len(test_loader)\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            correct_this, count_this = self.correct(x)\n",
    "            acc_all.append(correct_this / count_this * 100)\n",
    "\n",
    "        acc_all = np.asarray(acc_all)\n",
    "        acc_mean = np.mean(acc_all)\n",
    "        acc_std = np.std(acc_all)\n",
    "        print(f'Epoch {epoch} | Test Acc = {acc_mean:4.2f}% +- {1.96 * acc_std / np.sqrt(iter_num):4.2f}%')\n",
    "\n",
    "        if return_std:\n",
    "            return acc_mean, acc_std\n",
    "        else:\n",
    "            return acc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ProtoNet Implementation\n",
    "Now we are ready to extend the MetaTemplate with the ProtoNet specific implementation.\n",
    "\n",
    "Your task is to write the code for two functions: `set_forward` and `set_forward_loss`.\n",
    "\n",
    "1. `set_forward`: This function should calculate the prototypes (referred to as `support`) and queries (referred to as `embeddings`) for every data point. After that, determine the **similarity** between these prototypes and queries.\n",
    "2. `set_forward_loss`: With this function, your goal is to calculate the model's loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(MetaTemplate):\n",
    "    def __init__(self, backbone, n_way, n_support):\n",
    "        super(ProtoNet, self).__init__(backbone, n_way, n_support)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def set_forward(self, x):\n",
    "        # Compute the prototypes (support) and queries (embeddings) for each datapoint.\n",
    "        # Remember that you implemented a function to compute this before.\n",
    "        z_support, z_query = ...\n",
    "            \n",
    "        # Compute the prototype.\n",
    "        z_support = z_support.contiguous().view(self.n_way, self.n_support, -1)\n",
    "        z_proto = ...\n",
    "        \n",
    "        # Format the queries for the similarity computation.\n",
    "        z_query = z_query.contiguous().view(self.n_way * self.n_query, -1)\n",
    "\n",
    "        # Compute similarity score based on the euclidean distance between prototypes and queries.\n",
    "        scores = ...\n",
    "        return scores\n",
    "\n",
    "    def set_forward_loss(self, x):\n",
    "        # Compute the similarity scores between the prototypes and the queries.\n",
    "        scores = ...\n",
    "        \n",
    "        # Create the category labels for the queries.\n",
    "        y_query = ...\n",
    "        y_query = Variable(y_query)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = ...\n",
    "        return loss\n",
    "\n",
    "def euclidean_dist( x, y):\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# 2.0 Dataset - [SwissProt](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102476/)\n",
    "\n",
    "Now, let's dive into the world of proteins to test the power of the ProtoNet! ğŸ§¬\n",
    "\n",
    "Proteins are like intricate puzzles made up of smaller pieces known as amino acids. These tiny building blocks come together in a specific order to give a protein its unique structure and function in living organisms. It's like assembling LEGO blocks in a specific order to build a spaceship or a castle!\n",
    "\n",
    "Now, imagine we had a vast library of labels to describe each protein's function. Welcome to SwissProt dataset, which is annotated with Gene Ontology (GO) labels! The Gene Ontology Consortium (GOC), an international team of experts, crafted these labels to categorize the role, location, and function of genes across various species.\n",
    "\n",
    "The ontology includes over 47,000 terms (as of April 2018), each representing a specific characteristic or label. Think of these labels as descriptors that can be linked together. For instance, a protein might be described by its role in cell division, its location in the cell's nucleus, and its ability to bind to DNA. This results in a directed acyclic graph (DAG) structure of GO labels, where the nodes are the labels and the edges are the relationships between them. When a protein is linked to a specific label, it's also connected to all the labels that are ancestors in the DAG. This makes our machine learning challenge one of multi-label classification, meaning each protein can have multiple labels.\n",
    "\n",
    "For our exercise on fewshot learning, which mainly focuses on single-label classification, we need a method to assign just one label to each protein. We achieve this by choosing the most detailed label from the GO DAG for every protein. We've provided a procedure (get_samples_using_ic) that does this for you and also loads the dataset in the format you'll need.\n",
    "\n",
    "## 2.1 Creating a Dataset Template for the Few-Shot Task\n",
    "Let's keep our focus on our second objective: acquainting you with the `Few-Shot-Bench` code base. This library not only allows to measure the performance of various methods but also facilitates comparisons across multiple datasets. For this exercise, we'll start by examining the `FewShotDataset` template and SwissProt (SP) specialized version, the `SPDataset` before delving into the episodes data set for the SwissProt dataset, `SPSetDataset`, for the episodic training.\n",
    "\n",
    "**Note**: We're not expecting you to write any code for this. Instead, we want you to familiarize yourself with the code structure and understand the dataset's layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.check_init()\n",
    "\n",
    "    def check_init(self):\n",
    "        \"\"\"\n",
    "        Convenience function to check that the FewShotDataset is properly configured.\n",
    "        \"\"\"\n",
    "        required_attrs = ['_dataset_name', '_data_dir']\n",
    "        for attr in required_attrs:\n",
    "            if not hasattr(self, attr):\n",
    "                raise ValueError(f'FewShotDataset must have attribute {attr}.')\n",
    "\n",
    "        if not os.path.exists(self._data_dir):\n",
    "            raise ValueError(\n",
    "                f'{self._data_dir} does not exist yet. Please generate/download the dataset first.')\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def __getitem__(self, i):\n",
    "        return NotImplemented\n",
    "\n",
    "    @abstractmethod\n",
    "    def __len__(self):\n",
    "        return NotImplemented\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def dim(self):\n",
    "        return NotImplemented\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_data_loader(self, mode='train') -> DataLoader:\n",
    "        return NotImplemented\n",
    "\n",
    "    @property\n",
    "    def dataset_name(self):\n",
    "        \"\"\"\n",
    "        A string that identifies the dataset, e.g., 'swissprot'\n",
    "        \"\"\"\n",
    "        return self._dataset_name\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        return self._data_dir\n",
    "\n",
    "    def initialize_data_dir(self, root_dir):\n",
    "        os.makedirs(root_dir, exist_ok=True)\n",
    "        self._data_dir = os.path.join(root_dir, self._dataset_name)\n",
    "\n",
    "class SPDataset(FewShotDataset, ABC):\n",
    "    _dataset_name = 'swissprot'\n",
    "\n",
    "    def load_swissprot(self, level = 5, mode='train', min_samples = 20):\n",
    "        samples = get_samples_using_ic(root = self.data_dir)\n",
    "        samples = check_min_samples(samples, min_samples)\n",
    "        unique_ids = set(get_mode_ids(samples)[mode])\n",
    "        return [sample for sample in samples if sample.annot in unique_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Creating an Episode Dataset for the SwissProt Dataset\n",
    "\n",
    "\n",
    "In this exercise, you'll be working on creating an episode dataloader for the SwissProt dataset, which we need for training the ProtoNet model. Think of an episode dataset as a series of episodes, where each episode is made up of specific classes and their associated samples.\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "**Episode**: A group of n classes (n_way).\n",
    "\n",
    "**Each Class in an Episode**: Contains `k` support samples (`n_support`) used for training and `q` query (`n_query`) samples used for evaluating performance.\n",
    "\n",
    "Your task is to complete the episode dataloader `SPSetDataset` by creating a dataloaders for each category and implement the iterator function for the `EpisodicBatchSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTDIM = 1280\n",
    "\n",
    "class SubDataset(Dataset):\n",
    "    def __init__(self, samples, data_dir):\n",
    "        self.samples = samples\n",
    "        self.encoder = encodings(data_dir)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sample = self.samples[i]\n",
    "        return sample.input_seq, self.encoder[sample.annot]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return PROTDIM\n",
    "\n",
    "class EpisodicBatchSampler(object):\n",
    "    def __init__(self, n_classes, n_way, n_episodes):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_way = n_way\n",
    "        self.n_episodes = n_episodes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_episodes\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(self.n_episodes):\n",
    "            # Random sample the `n_way` classes for this episode.\n",
    "            # This is needed to return the indices for the selected category dataloaders for this episode.\n",
    "            yield ...\n",
    "\n",
    "class SPSetDataset(SPDataset):\n",
    "    def __init__(self, n_way, n_support, n_query, n_episode=100, root='./data', mode='train'):\n",
    "        self.initialize_data_dir(root)\n",
    "\n",
    "        self.n_way = n_way\n",
    "        self.n_episode = n_episode\n",
    "        min_samples = n_support + n_query\n",
    "        self.encoder = encodings(self.data_dir)\n",
    "\n",
    "        samples_all = self.load_swissprot(mode = mode, min_samples = min_samples)\n",
    "\n",
    "        self.categories = get_ids(samples_all) # Unique annotations\n",
    "        self.x_dim = PROTDIM\n",
    "\n",
    "        self.sub_dataloader = []\n",
    "\n",
    "        sub_data_loader_params = dict(batch_size=min_samples,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=0,  # use main thread only or may receive multiple batches\n",
    "                                      pin_memory=False)\n",
    "\n",
    "        # Create the sub datasets for each annotation of the categories and collect all the dataloaders in `self.sub_dataloader`.\n",
    "        ...\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Return the next batch of the dataloader of the i-th category.\n",
    "        return ...\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.categories)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.x_dim\n",
    "\n",
    "    def get_data_loader(self) -> DataLoader:\n",
    "        sampler = EpisodicBatchSampler(len(self), self.n_way, self.n_episode)\n",
    "        data_loader_params = dict(batch_sampler=sampler, num_workers=0, pin_memory=True)\n",
    "        data_loader = torch.utils.data.DataLoader(self, **data_loader_params)\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "# 3.0 Training and testing the model \n",
    "Now, we are going to train our Protonet model and see how it performs on the SwissProt dataset.\n",
    "\n",
    "**A heads up:** Loading the training dataset might take around 2 minutes and loading the test set about 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_way, n_support, n_query, n_train_episode):\n",
    "    # Load train dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "    train_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=n_train_episode, root='./data', mode='train')\n",
    "    train_loader = ...\n",
    "\n",
    "    # Load test dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "    test_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=100, root='./data', mode='test')\n",
    "    test_loader = ...\n",
    "\n",
    "    # Initialize a fully connected network `FCNet` in `fcnet.py` with two hidden layers of 512 units each as feature extractor.\n",
    "    backbone = ...\n",
    "\n",
    "    # Initialize model using the backbone and the optimizer.\n",
    "    model = ...\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    test_accs = []; train_losses = []\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "\n",
    "        # Implement training of the model. Remember to make use of functions defined in the `ProtoNet` and `MetaTemplate` class.\n",
    "        epoch_loss = ...\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Evaluate test performance for epoch. Remember to make use of functions defined in the `ProtoNet` and `MetaTemplate` class.\n",
    "        test_acc = ...\n",
    "        test_accs.append(test_acc)\n",
    "        print(f'Epoch {epoch} | Train Loss {epoch_loss} | Test Acc {test_acc}')\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 2.5))\n",
    "    ax1.plot(range(len(train_losses)), train_losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Train Loss')\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2.plot(range(len(test_accs)), test_accs)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Test Accuracy')\n",
    "    ax2.grid()\n",
    "    fig.suptitle(f\"n_way={n_way}, n_support={n_support}, n_query={n_query}, n_train_episode={n_train_episode}\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_way': 5, 'n_support': 5, 'n_query': 15, 'n_train_episode': 5}\n",
    "display_utils.sliders(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(**parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fewshotbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
