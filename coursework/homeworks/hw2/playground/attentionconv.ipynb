{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9991, 0.9997, 0.9999],\n",
       "        [0.9991, 0.9997, 0.9999],\n",
       "        [0.9991, 0.9997, 0.9999]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# -----Input setup\n",
    "# Triangle\n",
    "# 0 with 1, 2\n",
    "# 2 with 0, 1\n",
    "adj = torch.Tensor([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
    "X_prime = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "n_nodes, _ = X_prime.shape\n",
    "# Init S to be a column vector of size 3 x 1\n",
    "S = torch.Tensor([1, 1, 1, 1, 1, 1]).unsqueeze(1)\n",
    "\n",
    "\n",
    "# -----AttentionConv\n",
    "# Add self loop to adjaceny matrix\n",
    "adj = adj + torch.eye(n_nodes)\n",
    "\n",
    "# (2) Compute attention scores for each neighbor\n",
    "# (2a) Get all edges\n",
    "# E.g. if adj[i, j] = 1, then nbs will have an entry (i, j)\n",
    "# as well as (j, i) since the graph is undirected\n",
    "nbs = adj.nonzero() # of shape (2*num_edges, 2)\n",
    "i, j = nbs[:, 0], nbs[:, 1]\n",
    "\n",
    "# (2b) Concatenate each vector's v transformed features\n",
    "# with its neightbors' transformed features\n",
    "# E.g. if X_prime[i] = [1, 2] and X_prime[j] = [3, 4]\n",
    "# then x_prime_concat_all will include [[1, 2, 3, 4], [3, 4, 1, 2]]\n",
    "X_prime_i = X_prime[i] # Target vectors (vs)\n",
    "X_prime_j = X_prime[j] # Neighbor vectors (vnb)\n",
    "X_prime_concat_all = torch.cat([X_prime_i, X_prime_j], dim=1) # Shape: (2*num_edges, 2*out_features)\n",
    "\n",
    "# (2c) Compute the dot product between S and the concat. vector\n",
    "# of target vector i and its neighbor j (nb)\n",
    "# Note: (2*num_edges, 2*out_features) @ (2*out_features, 1) = (2*num_edges, 1)\n",
    "# --> squeeze result to get a 1D tensor of shape (2*num_edges, )\n",
    "E_i_nb = (X_prime_concat_all @ S).squeeze()\n",
    "\n",
    "# Apply leaky relu to get the raw attention scores\n",
    "raw_attention_scores = F.leaky_relu(E_i_nb)\n",
    "\n",
    "# (2d) Finally, apply the softmax function to get the attention weights\n",
    "# Map the values to positive range using exponential function\n",
    "exp_attention_scores = torch.exp(raw_attention_scores)\n",
    "\n",
    "# Create an array to hold the sum of exp. attention scores for each node\n",
    "# (i.e. the total attention of the node's neighborhood)\n",
    "neighborhood_sum = torch.zeros(n_nodes)\n",
    "\n",
    "# Sum the exp. attention scores for each node's neighborhood\n",
    "# Note:\n",
    "# 0 indicates dimnesion, here we just have one dimension so 0\n",
    "# i indicates the index of the node from edge (i, j)\n",
    "neighborhood_sum.index_add_(0, i, exp_attention_scores)\n",
    "\n",
    "# Divide the exponential scores by the sum of the neighborhood\n",
    "attention_scores = exp_attention_scores / neighborhood_sum[i]\n",
    "\n",
    "# (3) Compute the weighted sum of the neighbors'\n",
    "# Create summation mask of shape (# of nodes, 2*# of edges)\n",
    "# In simple terms, the mask indicates which edges is the given node i\n",
    "# associated with. E.g. if mask[i, j] = 1, then edge (i, j) is associated.\n",
    "mask = (i.view(-1, 1) == torch.arange(n_nodes)).T.to(torch.float32)\n",
    "\n",
    "# Weight the neighbors' features by the attention scores\n",
    "nbs_feat_weighted = attention_scores.view(-1, 1) * X_prime_j\n",
    "\n",
    "# Compute the weighted sum of the neighbors' x_prime\n",
    "weighted_sum = mask @ nbs_feat_weighted\n",
    "\n",
    "# Finally, apply sigmoid\n",
    "X_result = torch.sigmoid(weighted_sum)\n",
    "\n",
    "X_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs502",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
