wandb_version: 1

learning_rate:
  desc: null
  value: 0.01
architecture:
  desc: null
  value: GNN with 2 layers and 2625 trainable parameters.
conv_layers_type:
  desc: null
  value: '[<class ''scripts.layers.GraphAttentionConv''>, {''in_features'': 7, ''out_features'':
    64}]'
dataset:
  desc: null
  value: MUTAG
epochs:
  desc: null
  value: 200
batch_size:
  desc: null
  value: 64
optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay:\
    \ 1e-06\n)"
shuffle:
  desc: null
  value: false
pooling:
  desc: null
  value: MeanPool
dropout:
  desc: null
  value: 0.001
weight_decay:
  desc: null
  value: 1.0e-06
pos_weight:
  desc: null
  value: null
_wandb:
  desc: null
  value:
    python_version: 3.9.18
    cli_version: 0.15.12
    framework: torch
    is_jupyter_run: true
    is_kaggle_kernel: false
    start_time: 1698312526.940123
    t:
      1:
      - 1
      - 5
      - 49
      - 51
      - 53
      - 55
      2:
      - 1
      - 5
      - 49
      - 51
      - 53
      - 55
      3:
      - 1
      - 2
      - 16
      - 23
      4: 3.9.18
      5: 0.15.12
      8:
      - 1
      - 5
      13: darwin-x86_64
